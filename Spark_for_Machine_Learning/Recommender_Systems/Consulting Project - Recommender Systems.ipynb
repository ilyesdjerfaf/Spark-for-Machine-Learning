{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulting Project \n",
    "## Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole world seems to be hearing about your new amazing abilities to analyze big data and build useful systems for them! You've just taken up a new contract with a new online food delivery company. This company is trying to differentiate itself by recommending new meals to customers based off of other customers likings.\n",
    "\n",
    "Can you build them a recommendation system?\n",
    "\n",
    "Your final result should be in the form of a function that can take in a Spark DataFrame of a single customer's ratings for various meals and output their top 3 suggested meals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('meal_recommendation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv('Meal_Info.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+--------+--------------------+\n",
      "|mealId|rating|userId|mealskey|           meal_name|\n",
      "+------+------+------+--------+--------------------+\n",
      "|     2|   3.0|     0|     2.0|       Chicken Curry|\n",
      "|     3|   1.0|     0|     3.0|Spicy Chicken Nug...|\n",
      "|     5|   2.0|     0|     5.0|           Hamburger|\n",
      "|     9|   4.0|     0|     9.0|       Taco Surprise|\n",
      "|    11|   1.0|     0|    11.0|            Meatloaf|\n",
      "|    12|   2.0|     0|    12.0|        Ceaser Salad|\n",
      "|    15|   1.0|     0|    15.0|            BBQ Ribs|\n",
      "|    17|   1.0|     0|    17.0|         Sushi Plate|\n",
      "|    19|   1.0|     0|    19.0|Cheesesteak Sandw...|\n",
      "|    21|   1.0|     0|    21.0|             Lasagna|\n",
      "|    23|   1.0|     0|    23.0|      Orange Chicken|\n",
      "|    26|   3.0|     0|    26.0|    Spicy Beef Plate|\n",
      "|    27|   1.0|     0|    27.0|Salmon with Mashe...|\n",
      "|    28|   1.0|     0|    28.0| Penne Tomatoe Pasta|\n",
      "|    29|   1.0|     0|    29.0|        Pork Sliders|\n",
      "|    30|   1.0|     0|    30.0| Vietnamese Sandwich|\n",
      "|    31|   1.0|     0|    31.0|        Chicken Wrap|\n",
      "|    34|   1.0|     0|    null|       Cowboy Burger|\n",
      "|    37|   1.0|     0|    null|       Cowboy Burger|\n",
      "|    41|   2.0|     0|    null|       Cowboy Burger|\n",
      "+------+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As an information, we don't need the mealid we will work just with the mealskey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(\"mealId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   3.0|     0|     2.0|       Chicken Curry|\n",
      "|   1.0|     0|     3.0|Spicy Chicken Nug...|\n",
      "|   2.0|     0|     5.0|           Hamburger|\n",
      "|   4.0|     0|     9.0|       Taco Surprise|\n",
      "|   1.0|     0|    11.0|            Meatloaf|\n",
      "|   2.0|     0|    12.0|        Ceaser Salad|\n",
      "|   1.0|     0|    15.0|            BBQ Ribs|\n",
      "|   1.0|     0|    17.0|         Sushi Plate|\n",
      "|   1.0|     0|    19.0|Cheesesteak Sandw...|\n",
      "|   1.0|     0|    21.0|             Lasagna|\n",
      "|   1.0|     0|    23.0|      Orange Chicken|\n",
      "|   3.0|     0|    26.0|    Spicy Beef Plate|\n",
      "|   1.0|     0|    27.0|Salmon with Mashe...|\n",
      "|   1.0|     0|    28.0| Penne Tomatoe Pasta|\n",
      "|   1.0|     0|    29.0|        Pork Sliders|\n",
      "|   1.0|     0|    30.0| Vietnamese Sandwich|\n",
      "|   1.0|     0|    31.0|        Chicken Wrap|\n",
      "|   1.0|     0|    null|       Cowboy Burger|\n",
      "|   1.0|     0|    null|       Cowboy Burger|\n",
      "|   2.0|     0|    null|       Cowboy Burger|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates([\"rating\", \"userId\", \"mealskey\", \"meal_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   1.0|    22|      16|    Fried Rice Plate|\n",
      "|   1.0|    15|      13|Mandarin Chicken ...|\n",
      "|   2.0|    16|      30| Vietnamese Sandwich|\n",
      "|   1.0|    22|      26|    Spicy Beef Plate|\n",
      "|   4.0|    22|      32|       Cowboy Burger|\n",
      "|   1.0|    23|      12|        Ceaser Salad|\n",
      "|   5.0|    11|      27|Salmon with Mashe...|\n",
      "|   3.0|    12|      32|       Cowboy Burger|\n",
      "|   1.0|     5|      27|Salmon with Mashe...|\n",
      "|   1.0|     6|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|    23|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|    27|      29|        Pork Sliders|\n",
      "|   1.0|     3|      19|Cheesesteak Sandw...|\n",
      "|   1.0|     5|       4|Pretzels and Chee...|\n",
      "|   2.0|     7|      32|       Cowboy Burger|\n",
      "|   1.0|    18|      20|     Southwest Salad|\n",
      "|   1.0|    20|      32|       Cowboy Burger|\n",
      "|   2.0|     8|       4|Pretzels and Chee...|\n",
      "|   1.0|    18|       1|             Burrito|\n",
      "|   1.0|    24|       4|Pretzels and Chee...|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling the missing values in the **mealskey**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique meal names: 33\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique meal names\n",
    "unique_meal_count = df.select(\"meal_name\").distinct().count()\n",
    "\n",
    "print(\"Number of unique meal names:\", unique_meal_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "max_val = df.select(max(df['mealskey'])).collect()\n",
    "print(max_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min\n",
    "min_val = df.select(min(df['mealskey'])).collect()\n",
    "print(min_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique meal keys: 33\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique meal names\n",
    "unique_meal_count = df.select(\"mealskey\").distinct().count()\n",
    "\n",
    "print(\"Number of unique meal keys:\", unique_meal_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.fill(df.select(max(df['mealskey'])).collect()[0][0]+1,['mealskey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   3.0|     0|     2.0|       Chicken Curry|\n",
      "|   1.0|     0|     3.0|Spicy Chicken Nug...|\n",
      "|   2.0|     0|     5.0|           Hamburger|\n",
      "|   4.0|     0|     9.0|       Taco Surprise|\n",
      "|   1.0|     0|    11.0|            Meatloaf|\n",
      "|   2.0|     0|    12.0|        Ceaser Salad|\n",
      "|   1.0|     0|    15.0|            BBQ Ribs|\n",
      "|   1.0|     0|    17.0|         Sushi Plate|\n",
      "|   1.0|     0|    19.0|Cheesesteak Sandw...|\n",
      "|   1.0|     0|    21.0|             Lasagna|\n",
      "|   1.0|     0|    23.0|      Orange Chicken|\n",
      "|   3.0|     0|    26.0|    Spicy Beef Plate|\n",
      "|   1.0|     0|    27.0|Salmon with Mashe...|\n",
      "|   1.0|     0|    28.0| Penne Tomatoe Pasta|\n",
      "|   1.0|     0|    29.0|        Pork Sliders|\n",
      "|   1.0|     0|    30.0| Vietnamese Sandwich|\n",
      "|   1.0|     0|    31.0|        Chicken Wrap|\n",
      "|   1.0|     0|    32.0|       Cowboy Burger|\n",
      "|   1.0|     0|    32.0|       Cowboy Burger|\n",
      "|   2.0|     0|    32.0|       Cowboy Burger|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   3.0|     0|       2|       Chicken Curry|\n",
      "|   1.0|     0|       3|Spicy Chicken Nug...|\n",
      "|   2.0|     0|       5|           Hamburger|\n",
      "|   4.0|     0|       9|       Taco Surprise|\n",
      "|   1.0|     0|      11|            Meatloaf|\n",
      "|   2.0|     0|      12|        Ceaser Salad|\n",
      "|   1.0|     0|      15|            BBQ Ribs|\n",
      "|   1.0|     0|      17|         Sushi Plate|\n",
      "|   1.0|     0|      19|Cheesesteak Sandw...|\n",
      "|   1.0|     0|      21|             Lasagna|\n",
      "|   1.0|     0|      23|      Orange Chicken|\n",
      "|   3.0|     0|      26|    Spicy Beef Plate|\n",
      "|   1.0|     0|      27|Salmon with Mashe...|\n",
      "|   1.0|     0|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|     0|      29|        Pork Sliders|\n",
      "|   1.0|     0|      30| Vietnamese Sandwich|\n",
      "|   1.0|     0|      31|        Chicken Wrap|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   2.0|     0|      32|       Cowboy Burger|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"mealskey\", col(\"mealskey\").cast(\"int\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training, test) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   1.0|     0|       3|Spicy Chicken Nug...|\n",
      "|   1.0|     0|      11|            Meatloaf|\n",
      "|   1.0|     0|      17|         Sushi Plate|\n",
      "|   1.0|     0|      19|Cheesesteak Sandw...|\n",
      "|   1.0|     0|      21|             Lasagna|\n",
      "|   1.0|     0|      23|      Orange Chicken|\n",
      "|   1.0|     0|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|     0|      29|        Pork Sliders|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "|   1.0|     0|      32|       Cowboy Burger|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.dropDuplicates([\"rating\", \"userId\", \"mealskey\", \"meal_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+\n",
      "|rating|userId|mealskey|           meal_name|\n",
      "+------+------+--------+--------------------+\n",
      "|   1.0|    22|      16|    Fried Rice Plate|\n",
      "|   1.0|    15|      13|Mandarin Chicken ...|\n",
      "|   1.0|    23|      12|        Ceaser Salad|\n",
      "|   2.0|    16|      30| Vietnamese Sandwich|\n",
      "|   4.0|    22|      32|       Cowboy Burger|\n",
      "|   3.0|    12|      32|       Cowboy Burger|\n",
      "|   5.0|    11|      27|Salmon with Mashe...|\n",
      "|   1.0|     5|      27|Salmon with Mashe...|\n",
      "|   1.0|     6|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|    23|      28| Penne Tomatoe Pasta|\n",
      "|   1.0|     3|      19|Cheesesteak Sandw...|\n",
      "|   1.0|     5|       4|Pretzels and Chee...|\n",
      "|   1.0|    18|      20|     Southwest Salad|\n",
      "|   1.0|    20|      32|       Cowboy Burger|\n",
      "|   2.0|     7|      32|       Cowboy Burger|\n",
      "|   1.0|    18|       1|             Burrito|\n",
      "|   2.0|     8|       4|Pretzels and Chee...|\n",
      "|   1.0|    14|       9|       Taco Surprise|\n",
      "|   1.0|    26|       2|       Chicken Curry|\n",
      "|   1.0|    27|      28| Penne Tomatoe Pasta|\n",
      "+------+------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"mealskey\", ratingCol=\"rating\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+------------+\n",
      "|rating|userId|mealskey|           meal_name|  prediction|\n",
      "+------+------+--------+--------------------+------------+\n",
      "|   1.0|     1|       3|Spicy Chicken Nug...|   2.0916033|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     1|      32|       Cowboy Burger|   1.5863817|\n",
      "|   1.0|     3|       1|             Burrito|   0.6205207|\n",
      "|   1.0|     3|      32|       Cowboy Burger|   1.8170124|\n",
      "|   1.0|     3|      32|       Cowboy Burger|   1.8170124|\n",
      "|   1.0|     3|      32|       Cowboy Burger|   1.8170124|\n",
      "|   1.0|     4|       6|  Spicy Pork Sliders|  0.58239216|\n",
      "|   1.0|     2|      10|   Roasted Eggplant |   1.6947582|\n",
      "|   1.0|     2|      32|       Cowboy Burger|   1.9922881|\n",
      "|   1.0|     2|      32|       Cowboy Burger|   1.9922881|\n",
      "|   1.0|     2|      32|       Cowboy Burger|   1.9922881|\n",
      "|   1.0|     0|      15|            BBQ Ribs|  0.68825173|\n",
      "|   1.0|     0|      27|Salmon with Mashe...|-0.026277125|\n",
      "|   1.0|     0|      30| Vietnamese Sandwich|     3.03611|\n",
      "|   1.0|     0|      31|        Chicken Wrap|  0.20950171|\n",
      "+------+------+--------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Root-mean-square error = 1.3515775027108345\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "\n",
    "predictions.show()\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">IMPROVING !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+--------------------+----------+\n",
      "|rating|userId|mealskey|           meal_name|prediction|\n",
      "+------+------+--------+--------------------+----------+\n",
      "|   1.0|    28|       7|              Nachos|       2.0|\n",
      "|   1.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   2.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   3.0|    28|       0|        Cheese Pizza|       1.0|\n",
      "|   3.0|    28|      19|Cheesesteak Sandw...|       2.0|\n",
      "|   3.0|    28|      24|               Chili|       1.0|\n",
      "|   3.0|    28|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    26|       1|             Burrito|       0.0|\n",
      "|   1.0|    26|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    27|       9|       Taco Surprise|       1.0|\n",
      "|   1.0|    27|      25| Roast Beef Sandwich|       0.0|\n",
      "|   1.0|    27|      29|        Pork Sliders|       1.0|\n",
      "|   1.0|    27|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    27|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    27|      32|       Cowboy Burger|       1.0|\n",
      "|   1.0|    27|      32|       Cowboy Burger|       1.0|\n",
      "|   2.0|    26|      32|       Cowboy Burger|       1.0|\n",
      "+------+------+--------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = predictions.withColumn(\"prediction\", when(col(\"prediction\").cast(\"int\").cast(\"float\") >= 0, col(\"prediction\").cast(\"int\").cast(\"float\")).otherwise(0))\n",
    "predictions_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.484591990388747\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions_2)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE OUTPUT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(single_user):\n",
    "    reccomendations = model.transform(single_user)\n",
    "    reccomendations = reccomendations.orderBy('prediction',ascending=False)\n",
    "    reccomendations.show()\n",
    "    # Select the top 3 recommended meals\n",
    "    top_3_recommendations = reccomendations.select(\"mealskey\",\"meal_name\").limit(3)\n",
    "    return top_3_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_user = test.filter(test['userId']==11).select(['mealskey','userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------+\n",
      "|mealskey|userId|prediction|\n",
      "+--------+------+----------+\n",
      "|      25|    11| 2.3875515|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      32|    11|   2.18957|\n",
      "|      22|    11| 0.9296804|\n",
      "|      11|    11|0.27436477|\n",
      "+--------+------+----------+\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `meal_name` cannot be resolved. Did you mean one of the following? [`mealskey`, `prediction`, `userId`].;\n'Project [mealskey#252, 'meal_name]\n+- Sort [prediction#833 DESC NULLS LAST], true\n   +- Project [mealskey#252, userId#122, UDF(features#480, features#492) AS prediction#833]\n      +- Join LeftOuter, (CASE WHEN isnull(mealskey#252) THEN cast(raise_error(mealskey Ids MUST NOT be Null, NullType) as int) ELSE mealskey#252 END = id#491)\n         :- Join LeftOuter, (CASE WHEN isnull(userId#122) THEN cast(raise_error(userId Ids MUST NOT be Null, NullType) as int) ELSE userId#122 END = id#479)\n         :  :- Project [mealskey#252, userId#122]\n         :  :  +- Filter (userId#122 = 11)\n         :  :     +- Sample 0.8, 1.0, false, 995409244936955056\n         :  :        +- Sort [rating#121 ASC NULLS FIRST, userId#122 ASC NULLS FIRST, mealskey#252 ASC NULLS FIRST, meal_name#124 ASC NULLS FIRST], false\n         :  :           +- Project [rating#121, userId#122, cast(mealskey#226 as int) AS mealskey#252, meal_name#124]\n         :  :              +- Project [rating#121, userId#122, coalesce(nanvl(mealskey#123, cast(null as double)), cast(32.0 as double)) AS mealskey#226, meal_name#124]\n         :  :                 +- Project [rating#121, userId#122, mealskey#123, meal_name#124]\n         :  :                    +- Relation [mealId#120,rating#121,userId#122,mealskey#123,meal_name#124] csv\n         :  +- Project [_1#474 AS id#479, _2#475 AS features#480]\n         :     +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#474, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false, true) AS _2#475]\n         :        +- ExternalRDD [obj#473]\n         +- Project [_1#486 AS id#491, _2#487 AS features#492]\n            +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#486, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false, true) AS _2#487]\n               +- ExternalRDD [obj#485]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output(single_user)\u001b[39m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[57], line 6\u001b[0m, in \u001b[0;36moutput\u001b[0;34m(single_user)\u001b[0m\n\u001b[1;32m      4\u001b[0m reccomendations\u001b[39m.\u001b[39mshow()\n\u001b[1;32m      5\u001b[0m \u001b[39m# Select the top 3 recommended meals\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m top_3_recommendations \u001b[39m=\u001b[39m reccomendations\u001b[39m.\u001b[39;49mselect(\u001b[39m\"\u001b[39;49m\u001b[39mmealskey\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mmeal_name\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mlimit(\u001b[39m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m top_3_recommendations\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:3036\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2991\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2992\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m \n\u001b[1;32m   2994\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[39m    +-----+---+\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3036\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   3037\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `meal_name` cannot be resolved. Did you mean one of the following? [`mealskey`, `prediction`, `userId`].;\n'Project [mealskey#252, 'meal_name]\n+- Sort [prediction#833 DESC NULLS LAST], true\n   +- Project [mealskey#252, userId#122, UDF(features#480, features#492) AS prediction#833]\n      +- Join LeftOuter, (CASE WHEN isnull(mealskey#252) THEN cast(raise_error(mealskey Ids MUST NOT be Null, NullType) as int) ELSE mealskey#252 END = id#491)\n         :- Join LeftOuter, (CASE WHEN isnull(userId#122) THEN cast(raise_error(userId Ids MUST NOT be Null, NullType) as int) ELSE userId#122 END = id#479)\n         :  :- Project [mealskey#252, userId#122]\n         :  :  +- Filter (userId#122 = 11)\n         :  :     +- Sample 0.8, 1.0, false, 995409244936955056\n         :  :        +- Sort [rating#121 ASC NULLS FIRST, userId#122 ASC NULLS FIRST, mealskey#252 ASC NULLS FIRST, meal_name#124 ASC NULLS FIRST], false\n         :  :           +- Project [rating#121, userId#122, cast(mealskey#226 as int) AS mealskey#252, meal_name#124]\n         :  :              +- Project [rating#121, userId#122, coalesce(nanvl(mealskey#123, cast(null as double)), cast(32.0 as double)) AS mealskey#226, meal_name#124]\n         :  :                 +- Project [rating#121, userId#122, mealskey#123, meal_name#124]\n         :  :                    +- Relation [mealId#120,rating#121,userId#122,mealskey#123,meal_name#124] csv\n         :  +- Project [_1#474 AS id#479, _2#475 AS features#480]\n         :     +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#474, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false, true) AS _2#475]\n         :        +- ExternalRDD [obj#473]\n         +- Project [_1#486 AS id#491, _2#487 AS features#492]\n            +- SerializeFromObject [knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1 AS _1#486, staticinvoke(class org.apache.spark.sql.catalyst.expressions.UnsafeArrayData, ArrayType(FloatType,false), fromPrimitiveArray, knownnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, true, false, true) AS _2#487]\n               +- ExternalRDD [obj#485]\n"
     ]
    }
   ],
   "source": [
    "output(single_user).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
